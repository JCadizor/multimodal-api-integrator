import React, { useState, useEffect } from 'react';
import { View, Text, TouchableOpacity, StyleSheet, ScrollView, TextInput, Alert, ActivityIndicator, Switch, ImageBackground } from 'react-native';
import { router, useLocalSearchParams, useFocusEffect } from 'expo-router';
import MaterialIcons from '@expo/vector-icons/MaterialIcons';
import AsyncStorage from '@react-native-async-storage/async-storage';
import { Audio } from 'expo-av';
import MessageList from '../../components/MessageList';
import { 
  handleTTS, 
  handleSTT, 
  handleSTTWithLanguage,
  handleLanguageDetection, 
  retrieveAsyncStorageDataAsJson 
} from '../../scripts/utils';
import { startTextToTextStream } from '../../scripts/handleComunication';
import attendanceAPI from '../../scripts/attendanceAPI';
import { log } from '../../scripts/simpleLogger.js';

const CHAT_STORAGE_KEY = '@chat_messages';

export default function ChatRoom() {
  // PAR√ÇMETROS DE NAVEGA√á√ÉO
  const params = useLocalSearchParams();
  const initialMode = params.initialMode || 'text'; // 'text' ou 'voice'
  
  const [messages, setMessages] = useState([]);
  const [inputText, setInputText] = useState('');
  const [isLoading, setIsLoading] = useState(true);
  const [isAiTyping, setIsAiTyping] = useState(false);
  // Modo de voz baseado no par√¢metro de navega√ß√£o: 'voice' = true, 'text' = false
  const [isVoiceModeEnabled, setIsVoiceModeEnabled] = useState(initialMode === 'voice');
  const [isRecording, setIsRecording] = useState(false);
  const [recording, setRecording] = useState(null);
  const [recordedAudio, setRecordedAudio] = useState(null);
  const [configData, setConfigData] = useState({});
  const [isTTSPlaying, setIsTTSPlaying] = useState(false);

  // CARREGAMENTO INICIAL - useEffect para persist√™ncia
  useEffect(() => {
    log('Modo inicial do chat:', initialMode);
    
    // Configurar modo de voz baseado no par√¢metro de navega√ß√£o
    if (initialMode === 'voice') {
      log('üé§ Chat iniciado em modo VOZ - grava√ß√£o ativada automaticamente');
      setIsVoiceModeEnabled(true);
    } else {
      log('üìù Chat iniciado em modo TEXTO - input de texto ativado');
      setIsVoiceModeEnabled(false);
    }
    
    initializeChat();
  }, []);

  // RECARREGAR CONFIGURA√á√ïES QUANDO A TELA ENTRA EM FOCO
  useFocusEffect(
    React.useCallback(() => {
      log('üîÑ Tela em foco - recarregando configura√ß√µes...');
      loadConfig();
    }, [])
  );

  // FUN√á√ÉO DE INICIALIZA√á√ÉO DO CHAT
  const initializeChat = async () => {
    await loadMessages();
    await loadConfig();
    await setupAudio();
  };

  // CARREGAMENTO DE CONFIGURA√á√ïES - Carrega dados do AsyncStorage
  const loadConfig = async () => {
    try {
      const data = await retrieveAsyncStorageDataAsJson();
      if (data) {
        setConfigData(data);
        log('üîß Configura√ß√µes carregadas:', {
          selectedVoice: data.selectedVoice,
          selectedSTTModel: data.selectedSTTModel,
          defaultLanguage: data.defaultLanguage,
          attendanceApiKey: data.attendanceApiKey ? '***' : 'n√£o definida',
          attendanceBaseUrl: data.attendanceBaseUrl
        });
      } else {
        log('‚ö†Ô∏è Nenhuma configura√ß√£o encontrada - usando valores padr√£o');
      }
    } catch (error) {
      console.error(`[${new Date().toLocaleTimeString('pt-PT', {hour12: false, fractionalSecondDigits: 3})}] ‚ùå Erro ao carregar configura√ß√µes:`, error);
    }
  };

  // CONFIGURA√á√ÉO DE √ÅUDIO - Configurar modo de grava√ß√£o
  const setupAudio = async () => {
    try {
      await Audio.requestPermissionsAsync();
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });
    } catch (error) {
      console.error(`[${new Date().toLocaleTimeString('pt-PT', {hour12: false, fractionalSecondDigits: 3})}] Erro ao configurar √°udio:`, error);
    }
  };

  // FUN√á√ÉO DE CARREGAMENTO - L√™ dados do AsyncStorage
  const loadMessages = async () => {
    try {
      setIsLoading(true);
      const storedMessages = await AsyncStorage.getItem(CHAT_STORAGE_KEY);
      
      if (storedMessages) {
        // Parse dos dados JSON e convers√£o de timestamps
        const parsedMessages = JSON.parse(storedMessages).map(msg => ({
          ...msg,
          timestamp: new Date(msg.timestamp) // Reconstroi objeto Date
        }));
        setMessages(parsedMessages);
      } else {
        // Mensagens iniciais se n√£o houver dados salvos
        const initialMessages = [
          { id: 1, text: "Ol√°! Como posso ajud√°-lo hoje?", sender: "ai", timestamp: new Date() },
        ];
        setMessages(initialMessages);
        await saveMessages(initialMessages);
      }
    } catch (error) {
      console.error(`[${new Date().toLocaleTimeString('pt-PT', {hour12: false, fractionalSecondDigits: 3})}] Erro ao carregar mensagens:`, error);
      Alert.alert('Erro', 'Falha ao carregar conversas anteriores');
    } finally {
      setIsLoading(false);
    }
  };

  // FUN√á√ÉO DE SALVAMENTO - Persiste dados no AsyncStorage
  const saveMessages = async (messagesToSave) => {
    try {
      await AsyncStorage.setItem(CHAT_STORAGE_KEY, JSON.stringify(messagesToSave));
    } catch (error) {
      console.error(`[${new Date().toLocaleTimeString('pt-PT', {hour12: false, fractionalSecondDigits: 3})}] Erro ao salvar mensagens:`, error);
      Alert.alert('Erro', 'Falha ao salvar a conversa');
    }
  };

  // FUN√á√ÉO ATUALIZADA - Agora salva ap√≥s cada mensagem
  const sendMessage = async () => {
    if (inputText.trim()) { // Verifica se o texto n√£o est√° vazio
      const newMessage = {
        id: Date.now(), // Usando timestamp como ID √∫nico
        text: inputText.trim(),
        sender: "user",
        timestamp: new Date()
      };
      
      const updatedMessages = [...messages, newMessage];
      setMessages(updatedMessages);
      setInputText('');
      
      // PERSIST√äNCIA IMEDIATA - Salva ap√≥s adicionar mensagem do utilizador
      await saveMessages(updatedMessages);
      
      // Processar resposta da IA
      await processAIResponse(updatedMessages);
    }
  };

  // FUN√á√ÉO PARA PROCESSAR RESPOSTA DA IA
  const processAIResponse = async (currentMessages) => {
    // INDICADOR DE QUE A IA EST√Å PROCESSANDO
    setIsAiTyping(true);
    
    log('üìù Processando resposta da IA...');
    log('üîä Modo de voz:', isVoiceModeEnabled ? 'ATIVO' : 'INATIVO');
    
    try {
      const lastUserMessage = currentMessages[currentMessages.length - 1];
      const userQuery = lastUserMessage.text;
      
      // VERIFICAR SE √â UMA PERGUNTA SOBRE ASSIDUIDADE
      const attendanceKeywords = ['assiduidade', 'entrou', 'entrada', 'colaborador', 'funcion√°rio', 'trabalhador', 'hoje', 'hist√≥rico'];
      const isAttendanceQuery = attendanceKeywords.some(keyword => 
        userQuery.toLowerCase().includes(keyword)
      );

      if (isAttendanceQuery) {
        log('üè¢ Detectada pergunta sobre assiduidade, consultando API... gatilho =' + attendanceKeywords.find(keyword => userQuery.toLowerCase().includes(keyword)));
        await processAttendanceQuery(currentMessages, userQuery);
        return;
      }

      // PROCESSAMENTO NORMAL COM API DE CHAT
      await processNormalChatResponse(currentMessages);

    } catch (error) {
      console.error(`[${new Date().toLocaleTimeString('pt-PT', {hour12: false, fractionalSecondDigits: 3})}] ‚ùå Erro geral no processamento da IA:`, error);
      await createErrorResponse(currentMessages, 'Erro inesperado. Tente novamente.');
    }
  };

  // NOVA FUN√á√ÉO PARA PROCESSAR QUERIES DE ASSIDUIDADE
  const processAttendanceQuery = async (currentMessages, userQuery) => {
    try {
      log('üè¢ Processando query de assiduidade:', userQuery);
      
      // Criar mensagem inicial da IA
      const aiResponse = {
        id: Date.now() + 1,
        text: "Consultando dados de assiduidade...",
        sender: "ai",
        timestamp: new Date(),
        isStreaming: true
      };
      
      let tempMessages = [...currentMessages, aiResponse];
      setMessages(tempMessages);

      // Processar query com a API de assiduidade
      log('[chatRoom.js] processAttendanceQuery -> chamar fun√ß√£o processNaturalQuery com:', userQuery);
      const result = await attendanceAPI.processNaturalQuery(userQuery);
      
      let responseText;
      let queryType = 'general';

      if (result.success) {
        if (result.hasEntered !== undefined) {
          responseText = result.message;
          queryType = 'entry_check';
        } else {
          responseText = attendanceAPI.formatResponse(result, 'list');
          queryType = 'list';
        }
      } else {
        responseText = `N√£o consegui processar a consulta de assiduidade: ${result.error}`;
      }

      // Atualizar mensagem com resposta final
      aiResponse.text = responseText;
      aiResponse.isStreaming = false;
      aiResponse.isAttendanceResponse = true;
      
      const finalMessages = [...currentMessages, aiResponse];
      setMessages(finalMessages);
      await saveMessages(finalMessages);

      // TTS se modo voz estiver ativo
      if (isVoiceModeEnabled && responseText.trim()) {
        log('üîä Modo de voz ativo - Executando TTS para resposta de assiduidade...');
        try {
          if (configData.hostnameAPI_TTS && configData.portAPI) {
            await handleTTS(responseText, configData, setIsTTSPlaying);
          }
        } catch (error) {
          console.error('‚ùå Erro no TTS:', error);
        }
      }

      setIsAiTyping(false);

    } catch (error) {
      console.error('‚ùå Erro ao processar query de assiduidade:', error);
      await createErrorResponse(currentMessages, 'Erro ao consultar dados de assiduidade.');
    }
  };

  // FUN√á√ÉO PARA PROCESSAMENTO NORMAL DE CHAT
  const processNormalChatResponse = async (currentMessages) => {
    // Preparar mensagens para a API (formato esperado pela API)
    const lastUserMessage = currentMessages[currentMessages.length - 1];
    const prompt = lastUserMessage.text;
    
    // Converter hist√≥rico de mensagens para formato da API
    const apiMessages = currentMessages
      .filter(msg => msg.sender !== 'ai' || msg.text !== "Ol√°! Como posso ajud√°-lo hoje?") // Filtrar mensagem inicial
      .map(msg => ({
        role: msg.sender === 'user' ? 'user' : 'assistant',
        content: msg.text
      }));

    log('üì° Enviando para API:', { prompt, messages: apiMessages });

    // Criar mensagem inicial da IA (vazia, ser√° preenchida com streaming)
    const aiResponse = {
      id: Date.now() + 1,
      text: "",
      sender: "ai",
      timestamp: new Date(),
      isStreaming: true
    };
    
    let tempMessages = [...currentMessages, aiResponse];
    setMessages(tempMessages);
    await saveMessages(tempMessages);

    // Fun√ß√£o para processar dados recebidos do stream
    const onData = (content) => {
      aiResponse.text += content;
      tempMessages = [...currentMessages, { ...aiResponse }];
      setMessages(tempMessages);
    };

    // Fun√ß√£o chamada quando o stream termina
    const onDone = async () => {
      log('‚úÖ Stream finalizado. Resposta completa:', aiResponse.text);
      
      // Marcar como n√£o-streaming e salvar mensagem final
      aiResponse.isStreaming = false;
      const finalMessages = [...currentMessages, aiResponse];
      setMessages(finalMessages);
      await saveMessages(finalMessages);

      // INTEGRA√á√ÉO TTS SE O MODO VOZ ESTIVER ATIVO
      if (isVoiceModeEnabled && aiResponse.text.trim()) {
        log('üîä Modo de voz ativo - Executando TTS...');
        try {
          if (configData.hostnameAPI_TTS && configData.portAPI) {
            await handleTTS(aiResponse.text, configData, setIsTTSPlaying);
          } else {
            console.warn('‚ö†Ô∏è Configura√ß√µes n√£o dispon√≠veis para TTS');
            Alert.alert('Aviso', 'Configura√ß√µes de TTS n√£o dispon√≠veis');
          }
        } catch (error) {
          console.error('‚ùå Erro no TTS:', error);
          Alert.alert('Erro', 'Erro ao reproduzir resposta em √°udio');
        }
      }

      // REMOVER INDICADOR DE PROCESSAMENTO
      setIsAiTyping(false);
    };

    // Fun√ß√£o para tratar erros
    const onError = (error) => {
      console.error('‚ùå Erro na API de Text to Text:', error);
      createErrorResponse(currentMessages, 'Desculpe, ocorreu um erro ao processar sua mensagem. Tente novamente.');
    };

    // Iniciar stream da API
    await startTextToTextStream({
      prompt,
      messages: apiMessages,
      onData,
      onDone,
      onError
    });
  };

  // FUN√á√ÉO UTILIT√ÅRIA PARA CRIAR RESPOSTAS DE ERRO
  const createErrorResponse = async (currentMessages, errorMessage) => {
    const errorResponse = {
      id: Date.now() + 1,
      text: errorMessage,
      sender: "ai",
      timestamp: new Date(),
      isError: true
    };
    
    const errorMessages = [...currentMessages, errorResponse];
    setMessages(errorMessages);
    await saveMessages(errorMessages);
    setIsAiTyping(false);
    
    Alert.alert('Erro', errorMessage);
  };

  // FUN√á√ÉO UTILIT√ÅRIA - Limpar conversa (opcional)
  const clearChat = async () => {
    Alert.alert(
      'Limpar Conversa',
      'Tem certeza que deseja apagar toda a conversa?',
      [
        { text: 'Cancelar', style: 'cancel' },
        {
          text: 'Limpar',
          style: 'destructive',
          onPress: async () => {
            try {
              // Parar grava√ß√£o se estiver ativa
              if (recording) {
                await stopRecording();
              }
              
              await AsyncStorage.removeItem(CHAT_STORAGE_KEY);
              setMessages([]);
              setIsAiTyping(false);
              setIsRecording(false);
              setRecordedAudio(null);
              setIsTTSPlaying(false);
              
              Alert.alert('Sucesso', 'Conversa limpa com sucesso!');
            } catch (error) {
              Alert.alert('Erro', 'Falha ao limpar a conversa');
            }
          }
        }
      ]
    );
  };

  // FUN√á√ÉO PARA TOGGLE DE VOZ - Gerencia modo TTS/STT
  const toggleVoiceMode = () => {
    const newMode = !isVoiceModeEnabled;
    setIsVoiceModeEnabled(newMode);
    
    // Limpar estado de grava√ß√£o ao trocar modo
    if (!newMode && recording) {
      stopRecording();
    }
    
    // Feedback para o usu√°rio
    Alert.alert(
      'Modo de Voz',
      newMode 
        ? 'Modo de voz ativado! Pressione o bot√£o do microfone para gravar sua mensagem.' 
        : 'Modo de voz desativado. Voltando ao modo texto.',
      [{ text: 'OK' }]
    );
    
    log('üîä Modo de voz:', newMode ? 'ATIVADO' : 'DESATIVADO');
  };

  // FUN√á√ÉO PARA INICIAR GRAVA√á√ÉO DE VOZ
  const startRecording = async () => {
    try {
      log('üé§ Iniciando grava√ß√£o...');
      
      const { recording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );
      
      setRecording(recording);
      setIsRecording(true);
      console.log('üé§ Grava√ß√£o iniciada!');
      
    } catch (error) {
      console.error('‚ùå Erro ao iniciar grava√ß√£o:', error);
      Alert.alert('Erro', 'N√£o foi poss√≠vel iniciar a grava√ß√£o');
    }
  };

  // FUN√á√ÉO PARA PARAR GRAVA√á√ÉO
  const stopRecording = async () => {
    if (!recording) return;
    
    try {
      console.log('üõë Parando grava√ß√£o...');
      
      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      
      setRecording(null);
      setIsRecording(false);
      setRecordedAudio(uri);
      
      console.log('‚úÖ Grava√ß√£o salva em:', uri);
      
      // Processar √°udio gravado
      if (uri) {
        await processRecordedAudio(uri);
      }
      
    } catch (error) {
      console.error('‚ùå Erro ao parar grava√ß√£o:', error);
      Alert.alert('Erro', 'Erro ao processar grava√ß√£o');
    }
  };

  // FUN√á√ÉO PARA PROCESSAR √ÅUDIO GRAVADO
  const processRecordedAudio = async (audioUri) => {
    console.log('üîÑ Processando √°udio gravado...');
    
    try {
      // Verificar se temos configura√ß√µes
      if (!configData.hostnameAPI_TTS || !configData.portAPI) {
        console.warn('‚ö†Ô∏è Configura√ß√µes n√£o carregadas, usando transcri√ß√£o simulada');
        const simulatedTranscription = "Mensagem de √°udio transcrita (simulada)";
        await createMessageFromTranscription(simulatedTranscription, true, null, audioUri);
        return;
      }

      // 1. Primeira transcri√ß√£o com idioma padr√£o para detectar idioma
      console.log('üé§ Primeira transcri√ß√£o para detec√ß√£o de idioma...');
      const initialTranscription = await handleSTT(audioUri, configData);
      
      // 2. Detectar idioma do texto transcrito
      let detectedLanguage = null;
      let finalTranscription = initialTranscription;
      
      try {
        detectedLanguage = await handleLanguageDetection(initialTranscription, configData);
        console.log('üåç Idioma detectado:', detectedLanguage.name, `(${detectedLanguage.code})`);
        
        // 3. Se o idioma detectado for diferente do padr√£o, fazer nova transcri√ß√£o
        const detectedLangCode = detectedLanguage.code;
        const defaultLang = configData.defaultLanguage || 'pt'; // Usar idioma padr√£o configurado
        
        if (detectedLangCode !== defaultLang) {
          console.log(`üîÑ Re-transcrevendo √°udio com idioma detectado: ${detectedLangCode}`);
          finalTranscription = await handleSTTWithLanguage(audioUri, configData, detectedLangCode);
          console.log('‚úÖ Transcri√ß√£o final:', finalTranscription);
        } else {
          console.log('‚úÖ Idioma detectado coincide com padr√£o, usando transcri√ß√£o inicial');
        }
        
      } catch (langError) {
        console.warn('‚ö†Ô∏è Erro na detec√ß√£o de idioma:', langError);
        console.log('üìù Continuando com transcri√ß√£o inicial');
        // Continuar com a transcri√ß√£o inicial
      }
      
      // 4. Criar mensagem com informa√ß√µes finais
      await createMessageFromTranscription(finalTranscription, true, detectedLanguage, audioUri);
      
    } catch (error) {
      console.error('‚ùå Erro ao processar √°udio:', error);
      // Fallback para simula√ß√£o em caso de erro
      const fallbackTranscription = "Erro na transcri√ß√£o - mensagem simulada";
      await createMessageFromTranscription(fallbackTranscription, true, null, audioUri);
    }
  };

  // FUN√á√ÉO AUXILIAR - Criar mensagem a partir da transcri√ß√£o
  const createMessageFromTranscription = async (transcriptionText, isVoiceMessage = false, detectedLanguage = null, audioUri = null) => {
    const newMessage = {
      id: Date.now(),
      text: transcriptionText,
      sender: "user",
      timestamp: new Date(),
      isVoiceMessage,
      audioUri, // URI do √°udio gravado para playback
      detectedLanguage: detectedLanguage ? {
        code: detectedLanguage.code,
        name: detectedLanguage.name
      } : null
    };
    
    const updatedMessages = [...messages, newMessage];
    setMessages(updatedMessages);
    
    // Log informativo sobre o idioma detectado
    if (detectedLanguage) {
      console.log(`üìù Mensagem criada em ${detectedLanguage.name} (${detectedLanguage.code}): "${transcriptionText}"`);
    }
    
    // Salvar e processar resposta da IA
    await saveMessages(updatedMessages);
    await processAIResponse(updatedMessages);
  };

  return (
    <ImageBackground 
      source={require('../../assets/images/cropped-isep.jpg')} 
      style={styles.backgroundImage}
      imageStyle={{ opacity: 0.5 }}
    >
      <View style={styles.container}>
      <View style={styles.header}>
        <TouchableOpacity onPress={() => router.back()} style={styles.backButton}>
          <MaterialIcons name="arrow-back" size={24} color="white" />
        </TouchableOpacity>
        
        <View style={styles.headerCenter}>
          <Text style={styles.headerTitle}>Chat com IA</Text>
          <View style={styles.voiceModeContainer}>
            <MaterialIcons 
              name={isVoiceModeEnabled ? "record-voice-over" : "voice-over-off"} 
              size={16} 
              color="white" 
              style={styles.voiceIcon}
            />
            <Switch
              value={isVoiceModeEnabled}
              onValueChange={toggleVoiceMode}
              trackColor={{ false: '#767577', true: '#81b0ff' }}
              thumbColor={isVoiceModeEnabled ? '#f5dd4b' : '#f4f3f4'}
              style={styles.voiceSwitch}
            />
          </View>
        </View>
        
        <TouchableOpacity onPress={clearChat} style={styles.clearButton}>
          <MaterialIcons name="delete" size={20} color="white" />
        </TouchableOpacity>
      </View>
      
      <View style={styles.messagesContainer}>
        {isLoading ? (
          <View style={styles.loadingContainer}>
            <ActivityIndicator size="large" color="#007AFF" />
            <Text style={styles.loadingText}>Carregando conversa...</Text>
          </View>
        ) : (
          <>
            <MessageList messages={messages} configData={configData} />
            {isAiTyping && (
              <View style={styles.typingIndicator}>
                <ActivityIndicator size="small" color="#666" />
                <Text style={styles.typingText}>IA est√° a escrever...</Text>
              </View>
            )}
            {isTTSPlaying && (
              <View style={styles.ttsIndicator}>
                <ActivityIndicator size="small" color="#007AFF" />
                <Text style={styles.ttsText}>üîä Reproduzindo resposta...</Text>
              </View>
            )}
          </>
        )}
      </View>
      
      <View style={styles.inputContainer}>
        {isVoiceModeEnabled ? (
          // MODO DE VOZ - Bot√£o de grava√ß√£o
          <View style={styles.voiceInputContainer}>
            <TouchableOpacity 
              onPress={isRecording ? stopRecording : startRecording}
              style={[
                styles.recordButton, 
                isRecording && styles.recordButtonActive,
                isAiTyping && styles.recordButtonDisabled
              ]}
              disabled={isAiTyping}
            >
              {isRecording ? (
                <MaterialIcons name="stop" size={32} color="white" />
              ) : (
                <MaterialIcons name="mic" size={32} color="white" />
              )}
            </TouchableOpacity>
            <Text style={styles.recordingStatus}>
              {isRecording ? 'Gravando... Toque para parar' : 'Toque para gravar'}
            </Text>
          </View>
        ) : (
          // MODO TEXTO - Input normal
          <>
            <TextInput
              style={styles.textInput}
              value={inputText}
              onChangeText={setInputText}
              placeholder="Digite sua mensagem..."
              multiline
            />
            <TouchableOpacity 
              onPress={sendMessage} 
              style={[styles.sendButton, isAiTyping && styles.sendButtonDisabled]}
              disabled={isAiTyping}
            >
              {isAiTyping ? (
                <ActivityIndicator size="small" color="white" />
              ) : (
                <MaterialIcons name="send" size={24} color="white" />
              )}
            </TouchableOpacity>
          </>
        )}
      </View>
    </View>
    </ImageBackground>
  )
}

const styles = StyleSheet.create({
  backgroundImage: {
    flex: 1,
    resizeMode: 'cover',
  },
  container: {
    flex: 1,
    backgroundColor: 'rgba(245, 245, 245, 0.7)', // Background semi-transparente
  },
  header: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'space-between',
    backgroundColor: '#007AFF',
    paddingTop: 40,
    paddingBottom: 10,
    paddingHorizontal: 15,
  },
  backButton: {
    marginRight: 15,
  },
  clearButton: {
    padding: 5,
  },
  headerCenter: {
    flex: 1,
    alignItems: 'center',
  },
  headerTitle: {
    color: 'white',
    fontSize: 18,
    fontWeight: 'bold',
    marginBottom: 4,
  },
  voiceModeContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    backgroundColor: 'rgba(255, 255, 255, 0.2)',
    borderRadius: 15,
    paddingHorizontal: 8,
    paddingVertical: 2,
  },
  voiceIcon: {
    marginRight: 4,
  },
  voiceSwitch: {
    transform: [{ scaleX: 0.8 }, { scaleY: 0.8 }],
  },
  loadingContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  loadingText: {
    fontSize: 16,
    color: '#666',
  },
  messagesContainer: {
    flex: 1,
    padding: 10,
  },
  inputContainer: {
    flexDirection: 'row',
    alignItems: 'flex-end',
    paddingHorizontal: 10,
    paddingVertical: 10,
    backgroundColor: 'rgba(255, 255, 255, 0.95)', // Mais vis√≠vel com transpar√™ncia
    borderTopWidth: 1,
    borderTopColor: '#e0e0e0',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: -1 },
    shadowOpacity: 0.1,
    shadowRadius: 2,
    elevation: 3,
  },
  voiceInputContainer: {
    flex: 1,
    alignItems: 'center',
    paddingVertical: 10,
  },
  recordButton: {
    backgroundColor: '#007AFF',
    borderRadius: 35,
    width: 70,
    height: 70,
    justifyContent: 'center',
    alignItems: 'center',
    marginBottom: 8,
  },
  recordButtonActive: {
    backgroundColor: '#FF3B30',
  },
  recordButtonDisabled: {
    backgroundColor: '#cccccc',
  },
  recordingStatus: {
    fontSize: 14,
    color: '#666',
    textAlign: 'center',
  },
  textInput: {
    flex: 1,
    borderWidth: 1,
    borderColor: '#e0e0e0',
    borderRadius: 20,
    paddingHorizontal: 15,
    paddingVertical: 10,
    marginRight: 10,
    maxHeight: 100,
    backgroundColor: '#f9f9f9',
  },
  sendButton: {
    backgroundColor: '#007AFF',
    borderRadius: 20,
    padding: 10,
    justifyContent: 'center',
    alignItems: 'center',
  },
  sendButtonDisabled: {
    backgroundColor: '#cccccc',
  },
  typingIndicator: {
    flexDirection: 'row',
    alignItems: 'center',
    paddingHorizontal: 15,
    paddingVertical: 10,
    backgroundColor: 'rgba(240, 240, 240, 0.95)', // Mais vis√≠vel com transpar√™ncia
    borderRadius: 15,
    marginVertical: 5,
    alignSelf: 'flex-start',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.2,
    shadowRadius: 2,
    elevation: 2,
  },
  typingText: {
    marginLeft: 8,
    fontSize: 14,
    color: '#666',
    fontStyle: 'italic',
  },
  ttsIndicator: {
    flexDirection: 'row',
    alignItems: 'center',
    paddingHorizontal: 15,
    paddingVertical: 10,
    backgroundColor: 'rgba(230, 243, 255, 0.95)', // Mais vis√≠vel com transpar√™ncia
    borderRadius: 15,
    marginVertical: 5,
    alignSelf: 'flex-start',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.2,
    shadowRadius: 2,
    elevation: 2,
  },
  ttsText: {
    marginLeft: 8,
    fontSize: 14,
    color: '#007AFF',
    fontStyle: 'italic',
  }
})